{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import mysql.connector\n",
    "import string\n",
    "import secrets\n",
    "import random\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "\ts.strip()\n",
    "\ts=re.sub(\"\\n+\",\"\\r\",s)\n",
    "\ts=re.sub(r\"\\s+\",\" \",s)\n",
    "\treturn s\n",
    "\n",
    "def digits(s):\n",
    "\treturn re.sub(\"\\D\",\"\",s)\n",
    "\n",
    "def log(s):\n",
    "\twith open(\"tem.txt\",\"w\") as f:\n",
    "\t\tf.write(clean(str(s)))\n",
    "\n",
    "def get(link):\n",
    "\tresponse=requests.get(link)\n",
    "\treturn BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "def generate_password(length=15):\n",
    "\tcharacters = string.ascii_letters + string.digits + string.punctuation\n",
    "\tpassword = ''.join(secrets.choice(characters) for i in range(length))\n",
    "\treturn password\n",
    "\n",
    "def generate_date():\n",
    "\tstart_date = datetime.date(1970, 4, 1)\n",
    "\tend_date = datetime.date(2003, 4, 10)\n",
    "\tr=random.choice([start_date + datetime.timedelta(n) for n in range((end_date - start_date).days + 1)])\n",
    "\treturn str(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://books.toscrape.com/\"\n",
    "soup=get(url)\n",
    "categories={}\n",
    "cats=soup.find_all(\"ul\")[1].find_all(\"li\")\n",
    "\n",
    "for cat in cats:\n",
    "\tlink=url+cat.find(\"a\").get(\"href\") \n",
    "\tcategories[cat]=link\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=list(soup.find_all(\"article\"))\n",
    "nxt=soup.find(\"li\",string=\"next\")\n",
    "link=url+nxt.find(\"a\").get(\"href\")\n",
    "second=get(link)\n",
    "articles+=second.find_all(\"article\")\n",
    "nxt=second.find(\"li\",string=\"next\")\n",
    "while  nxt is not  None:\n",
    "\tlink=url+\"catalogue/\"+second.find(\"a\",string=\"next\").get(\"href\")\n",
    "\tsecond=get(link)\n",
    "\tarticles+=second.find_all(\"article\")\n",
    "\tnxt=second.find(\"li\",string=\"next\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages=[]\n",
    "\n",
    "for article in articles:\n",
    "\tlink=article.find(\"h3\").find(\"a\").get(\"href\")\n",
    "\tif link.startswith(\"catalogue/\"):\n",
    "\t\tlink=url+link\n",
    "\telse:\n",
    "\t\tlink=url+\"catalogue/\"+link\n",
    "\tpages.append(get(link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "books=[]\n",
    "images=[]\n",
    "for page in pages:\n",
    "\tbook={}\n",
    "\timage={}\n",
    "\tbook[\"title\"]=clean(page.find(\"title\").text).replace(\" | Books to Scrape - Sandbox \",\"\")\n",
    "\tbook[\"category\"]=clean(page.find_all(\"li\")[2].text[1:])\n",
    "\tbook[\"description\"]=clean(page.find_all(\"p\")[3].text)\n",
    "\timage[\"img\"]=page.find(\"img\").get(\"src\")[6:]\n",
    "\timage[\"alt\"]=page.find(\"img\").get(\"alt\")\n",
    "\tinfo=[clean(i.text) for i in page.find_all(\"td\")]\n",
    "\tbook[\"upc\"]=info[0]\n",
    "\timage[\"upc\"]=info[0]\n",
    "\tbook[\"type\"]=info[1]\n",
    "\tbook[\"price\"]=float(info[2][1:])\n",
    "\tbook[\"tax\"]=float(digits(info[4]))\n",
    "\tbook[\"stock\"]=int(digits(info[5]))\n",
    "\tbook[\"rating\"]=0\n",
    "\tbook[\"reviews\"]=int(digits(info[6]))\n",
    "\tbooks.append(book)\n",
    "\timages.append(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"categories.csv\",\"w\",newline='')\n",
    "writer=csv.DictWriter(file,fieldnames=[\"category\",\"link\"])\n",
    "writer.writeheader()\n",
    "\n",
    "\n",
    "for cat,link in categories.items():\n",
    "\trow={\"category\":cat,\"link\":link}\n",
    "\twriter.writerow(row)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"books.csv\",\"w\",newline='',encoding=\"utf-8\")\n",
    "writer=csv.DictWriter(file,fieldnames=books[0].keys())\n",
    "writer.writeheader()\n",
    "writer.writerows(books)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"images.csv\",\"w\",newline='') as file:\n",
    "\twriter=csv.DictWriter(file,images[0].keys())\n",
    "\twriter.writeheader()\n",
    "\twriter.writerows(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "for book in books:\n",
    "\tpath=book[\"img\"]\n",
    "\tr=requests.get(url+path)\n",
    "\tos.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\twith open(path,\"wb\") as img:\n",
    "\t\timg.write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysql.connector.connect(\n",
    "\thost=\"localhost\",\n",
    "\tuser=\"root\",\n",
    "\tpassword=\"ahmedfarid\",\n",
    "\tdatabase=\"store\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('books.csv', newline='', encoding='utf-8') as file:\n",
    "\treader = csv.reader(file)\n",
    "\tnext(reader)\n",
    "\tfor row in reader:\n",
    "\t\tsql = \"INSERT INTO product(upc, name, type, category,description, stock, price, tax,rating, reviews) VALUES ( %s , %s , %s , %s , %s , %s , %s , %s , %s ,%s)\"\n",
    "\t\tvalues = tuple(row)\n",
    "\t\tprint(int(values[5]))\n",
    "\t\tcursor.execute(sql, values)\n",
    "\t\tdb.commit()\n",
    "print(\"Data inserted successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('images.csv', newline='', encoding='utf-8') as file:\n",
    "\treader = csv.reader(file)\n",
    "\tnext(reader)\n",
    "\tfor row in reader:\n",
    "\t\tsql = \"INSERT INTO image(upc,file,alt ) VALUES ( %s , %s , %s )\"\n",
    "\t\twith open(row[1],\"rb\") as imgFile:\n",
    "\t\t\trow[1]=imgFile.read()\n",
    "\t\t\tvalues = tuple(row)\n",
    "\t\t\tcursor.execute(sql, values)\n",
    "\t\t\tdb.commit()\n",
    "print(\"Data inserted successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"delete from user;\"\n",
    "\n",
    "cursor.execute(sql)\n",
    "db.commit()\n",
    "with open(\"users.csv\") as file:\n",
    "\treader=csv.reader(file)\n",
    "\tnext(reader)\n",
    "\tfor row in reader:\n",
    "\t\tsql=\"insert into user(city,country,fname,lname,email,dob,password)values(%s,%s,%s,%s,%s,%s,%s)\"\n",
    "\t\trow.append(row[2]+\".\"+row[3]+str(random.randrange(100000))+\"@domain.com\")\n",
    "\t\trow.append(generate_date())\n",
    "\t\trow.append(generate_password())\n",
    "\t\tcursor.execute(sql,tuple(row))\n",
    "\t\tdb.commit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
